 # ---------------------------------------------------------------------------- #
 #                      Config for Text2CAD Model Training                      #
 # ---------------------------------------------------------------------------- #
 
 
 
 # ---------------------- Configuration for text encoder ---------------------- #
text_encoder:
  # ----------------- Configuration for the Base Text Embedder ----------------- #
  text_embedder:
    # Name of the text encoder model
    model_name: "/data2/songyuan/models/AI-ModelScope/bert-large-uncased/AI-ModelScope/bert-large-uncase"
    # Maximum Text Sequence Length
    max_seq_len: 512
    # Cache Directory，有啥作用
    cache_dir: "/home/songyuan/disk/117/text2cad/Text2CAD/models/Text2CAD_1.0.pth"

  # ----------------- Configuration for the Adaptive Layer ----------------- #
  # MLP
  adaptive_layer:
    # Input dimension of the text encoder (1024 for bert, else 4096)
    in_dim: 1024 
    # Output dimension of the text encoder (1024 for bert, else 4096)
    out_dim: 1024
    # Number of attention heads in the text encoder
    num_heads: 8
    # Dropout probability in the text encoder
    dropout: 0.1

# ----------------------- Configuration for CAD Decoder ---------------------- #
cad_decoder:
  # Dimension of the latent variable z in the CAD decoder (1024 for bert, else 4096)
  tdim: 1024
  # Dimension of the state variable s in the CAD decoder
  cdim: 256
  # Number of transformer layers in the CAD decoder
  num_layers: 8
  # Number of attention heads in each layer of the CAD decoder
  num_heads: 8
  # Dropout probability in the CAD decoder
  dropout: 0.1
  # Starting level for channel attention in the CAD decoder
  ca_level_start: 2

# --------------- Configuration related to training dataloader --------------- #
train_data:
  # Root directory of the training data；3D模型特征向量
  cad_seq_dir: "/home/songyuan/disk/117/text2cad/Text2CAD/datasets/cad_seq/cad_seq_test"
  # Path to the CSV file containing the text prompts；prompt+command sequence，提示词+cad构建指令序列
  prompt_path: "/home/songyuan/disk/117/text2cad/Text2CAD/datasets/text2cad_v1.0.csv"
  # JSON file containing information about train, test, and validation splits
  split_filepath: "/home/songyuan/disk/117/text2cad/Text2CAD/datasets/train_test_val.json"
  # Maximum sequence length for input data
  max_seq_len: 512

# --------------------- Configuration related to training -------------------- #
train:
  # Learning rate for training
  lr: 0.0001
  # Batch size for training
  batch_size: 16 # for 80 GB gpu
  # Number of epochs for training
  num_epochs: 150
  # Number of workers for the DataLoader during training
  num_workers: 30
  # Prefetch factor for the DataLoader during training
  prefetch_factor: 10
  # Directory for logging training information
  log_dir: "/home/songyuan/disk/117/text2cad/Text2CAD/logs/"
  # Path to saved model checkpoint for Resuming Training (optional)
  checkpoint_path:  # Set to None if no checkpoint is available
  # Checkpoint interval
  checkpoint_interval: 10
  # Curriculum learning epoch (set to 0 for no curriculum learning)；课程学习算法：https://zhuanlan.zhihu.com/p/362351969
  curriculum_learning_epoch: 0
  

# ------------------------- Validation configuration ------------------------- #
val:
  # Nucleus sampling probability for validation (set to 0 for greedy decoding)
  nucleus_prob: 0
  val_batch: 5

# ------------------------------ Debug mode flag ----------------------------- #
# In debug mode, the model weights are not saved
debug: False

# --------------- Additional information (leave empty for now) --------------- #
info: "Experiment 1: Base Model Training"
